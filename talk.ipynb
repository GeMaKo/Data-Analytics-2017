{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "### Me: Gerrit Korff\n",
    "\n",
    "\n",
    "### Ancud IT-Beratung [ancud.de](https://ancud.de)\n",
    "![ancud](figs/ancud.png)\n",
    "\n",
    "\n",
    "### This talk: [github.com/GeMaKo/Data-Analytics-2017](https://github.com/GeMaKo/Data-Analytics-2017)\n",
    "#### Requirements: python3, ipython, notebook (jupyter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Neural Networks\n",
    "\n",
    "### A single neuron\n",
    "\n",
    "![spiking neural network](http://lis2.epfl.ch/CompletedResearchProjects/EvolutionOfAdaptiveSpikingCircuits/images/neuron.jpg)\n",
    "\n",
    "![spiking system](http://lis2.epfl.ch/CompletedResearchProjects/EvolutionOfAdaptiveSpikingCircuits/images/spiking.jpg)\n",
    "\n",
    "### Artificial neuron\n",
    "[Source](http://natureofcode.com/book/chapter-10-neural-networks/)\n",
    "\n",
    "![](http://natureofcode.com/book/imgs/chapter10/ch10_05.png)\n",
    "\n",
    "#### Add bias\n",
    "![](http://natureofcode.com/book/imgs/chapter10/ch10_06.png)\n",
    "\n",
    "\n",
    "#### Feed the data\n",
    "![](http://natureofcode.com/book/imgs/chapter10/ch10_07.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo [here](http://natureofcode.com/book/chapter-10-neural-networks/)\n",
    "\n",
    "### Linearly separable, and not\n",
    "![](http://natureofcode.com/book/imgs/chapter10/ch10_11.png)\n",
    "\n",
    "\n",
    "#### Logic example:\n",
    "![](http://natureofcode.com/book/imgs/chapter10/ch10_12.png)\n",
    "![](http://natureofcode.com/book/imgs/chapter10/ch10_13.png)\n",
    "\n",
    "#### Multilayer perceptron\n",
    "![](http://natureofcode.com/book/imgs/chapter10/ch10_14.png)\n",
    "\n",
    "### Activation Functions: [wiki](https://en.wikipedia.org/wiki/Activation_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architectures\n",
    "\n",
    "### Feedforward\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Artificial_neural_network.svg/560px-Artificial_neural_network.svg.png)\n",
    "\n",
    "\n",
    "### Recurrent\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/7/79/Recurrent_ann_dependency_graph.png)\n",
    "\n",
    "\n",
    "#### Elman SRNN\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/8/8f/Elman_srnn.png)\n",
    "\n",
    "### Unsupervised, eg. SOM\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Somtraining.svg/1000px-Somtraining.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New developments\n",
    "\n",
    "### General-purpose computing on graphics processing units (GPGPU)\n",
    "\n",
    "#### GPU vs CPU\n",
    "![](http://www.frontiersin.org/files/Articles/70265/fgene-04-00266-HTML/image_m/fgene-04-00266-g001.jpg)\n",
    "\n",
    "\n",
    "#### 2005\n",
    "![](figs/gpgpu.png)\n",
    "\n",
    "\n",
    "### Better algorithms\n",
    "\n",
    "#### 2011\n",
    "![](figs/2011-conv-mnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Convolutional Neural Networks (CNN)\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/6/63/Typical_cnn.png)\n",
    "\n",
    "### Weight Sharing, Convolution\n",
    "\n",
    "### Subsampling / Max Pooling\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/e/e9/Max_pooling.png)\n",
    "\n",
    "### Dropout, {L1, L2} regularization, artificial data, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST\n",
    "\n",
    "![](http://andrea.burattin.net/public-files/stuff/handwritten-digit-recognition/example_mnist.gif)\n",
    "\n",
    "![](figs/mnist-perfs.png)\n",
    "\n",
    "### Based on keras examples, specifically [this one](https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /opt/anaconda/anaconda3/lib/python3.6/site-packages\n",
      "Requirement already satisfied: tensorflow in /opt/anaconda/anaconda3/lib/python3.6/site-packages\n",
      "Requirement already satisfied: six in /opt/anaconda/anaconda3/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda/anaconda3/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: theano in /opt/anaconda/anaconda3/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/anaconda/anaconda3/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda/anaconda3/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: bleach==1.5.0 in /opt/anaconda/anaconda3/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: backports.weakref==1.0rc1 in /opt/anaconda/anaconda3/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: protobuf>=3.2.0 in /opt/anaconda/anaconda3/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /opt/anaconda/anaconda3/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /opt/anaconda/anaconda3/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: html5lib==0.9999999 in /opt/anaconda/anaconda3/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/anaconda/anaconda3/lib/python3.6/site-packages (from theano->keras)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda/anaconda3/lib/python3.6/site-packages/setuptools-27.2.0-py3.6.egg (from protobuf>=3.2.0->tensorflow)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (60000,)\n",
      "y_train shape: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "print('y_train shape:', y_train.shape)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y_train shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the convolutional neural network, layer by layer\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Definition of the learning process\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "# Model data\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 173s - loss: 0.3292 - acc: 0.9002 - val_loss: 0.0773 - val_acc: 0.9744\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 195s - loss: 0.1106 - acc: 0.9682 - val_loss: 0.0494 - val_acc: 0.9844\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 187s - loss: 0.0846 - acc: 0.9754 - val_loss: 0.0419 - val_acc: 0.9867\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 185s - loss: 0.0705 - acc: 0.9794 - val_loss: 0.0395 - val_acc: 0.9869\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 185s - loss: 0.0631 - acc: 0.9815 - val_loss: 0.0365 - val_acc: 0.9881\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 190s - loss: 0.0550 - acc: 0.9838 - val_loss: 0.0324 - val_acc: 0.9898\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 191s - loss: 0.0523 - acc: 0.9846 - val_loss: 0.0336 - val_acc: 0.9890\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 200s - loss: 0.0455 - acc: 0.9867 - val_loss: 0.0304 - val_acc: 0.9899\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 201s - loss: 0.0434 - acc: 0.9873 - val_loss: 0.0307 - val_acc: 0.9895\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 216s - loss: 0.0401 - acc: 0.9878 - val_loss: 0.0290 - val_acc: 0.9905\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 208s - loss: 0.0388 - acc: 0.9882 - val_loss: 0.0289 - val_acc: 0.9904\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 198s - loss: 0.0368 - acc: 0.9893 - val_loss: 0.0280 - val_acc: 0.9906\n",
      "Test loss: 0.0280344603432\n",
      "Test accuracy: 0.9906\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good old scikit-learn & linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda/anaconda3/lib/python3.6/site-packages (from sklearn)\n",
      "Installing collected packages: sklearn\n",
      "Successfully installed sklearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('variance filter', VarianceThreshold(threshold=0.01)), ('standard_scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('estimator', Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=2000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('variance filter', VarianceThreshold(threshold=0.01)),\n",
    "    ('standard_scale', StandardScaler()),\n",
    "    ('estimator', Lasso(alpha=0.1, max_iter=2000)),\n",
    "])\n",
    "\n",
    "pipeline.fit(x_train.reshape(60000, -1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47801019841269715"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "label_ranking_average_precision_score(y_test, pipeline.predict(x_test.reshape(len(x_test), -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99470000000000003"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_ranking_average_precision_score(y_test, model.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter visualization\n",
    "\n",
    "![](figs/stitched_filters_4x4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "![](figs/normal.jpg)\n",
    "\n",
    "### Adding classes\n",
    "\n",
    "![](figs/added-nodes.jpg)\n",
    "\n",
    "### Dimentionality reduction / Transfer learning\n",
    "\n",
    "![](figs/dimentionality-reduction.jpg)\n",
    "\n",
    "![](figs/dimentionality-reduction-2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final remarks\n",
    "\n",
    " - Usecases with not enough data\n",
    " - Usecases with many small models\n",
    " - Gain on performance vs. cost\n",
    " - Network architecture & hyperparameters\n",
    " - Deployment\n",
    "   - Cleanup\n",
    "   - Batching\n",
    "   - Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['conv2d_1', 'conv2d_2', 'max_pooling2d_1', 'dropout_1', 'flatten_1', 'dense_1', 'dropout_2', 'dense_2'])\n"
     ]
    }
   ],
   "source": [
    "# get the symbolic outputs of each \"key\" layer.\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "print(layer_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing filter 0\n",
      "Current loss value: 1.70963\n",
      "Current loss value: 2.03946\n",
      "Current loss value: 2.37792\n",
      "Current loss value: 2.72286\n",
      "Current loss value: 3.07352\n",
      "Current loss value: 3.43072\n",
      "Current loss value: 3.79163\n",
      "Current loss value: 4.15768\n",
      "Current loss value: 4.52956\n",
      "Current loss value: 4.90569\n",
      "Current loss value: 5.28502\n",
      "Current loss value: 5.66755\n",
      "Current loss value: 6.05594\n",
      "Current loss value: 6.44781\n",
      "Current loss value: 6.84326\n",
      "Current loss value: 7.2431\n",
      "Current loss value: 7.64671\n",
      "Current loss value: 8.05558\n",
      "Current loss value: 8.46875\n",
      "Current loss value: 8.88523\n",
      "Filter 0 processed in 0s\n",
      "Processing filter 1\n",
      "Current loss value: 2.34738\n",
      "Current loss value: 2.74086\n",
      "Current loss value: 3.14125\n",
      "Current loss value: 3.55094\n",
      "Current loss value: 3.97054\n",
      "Current loss value: 4.39407\n",
      "Current loss value: 4.82369\n",
      "Current loss value: 5.25712\n",
      "Current loss value: 5.69266\n",
      "Current loss value: 6.12828\n",
      "Current loss value: 6.56576\n",
      "Current loss value: 7.00641\n",
      "Current loss value: 7.44956\n",
      "Current loss value: 7.8928\n",
      "Current loss value: 8.33686\n",
      "Current loss value: 8.78317\n",
      "Current loss value: 9.23104\n",
      "Current loss value: 9.68117\n",
      "Current loss value: 10.1319\n",
      "Current loss value: 10.5827\n",
      "Filter 1 processed in 0s\n",
      "Processing filter 2\n",
      "Current loss value: 2.48999\n",
      "Current loss value: 2.88636\n",
      "Current loss value: 3.28274\n",
      "Current loss value: 3.67936\n",
      "Current loss value: 4.0769\n",
      "Current loss value: 4.47622\n",
      "Current loss value: 4.87804\n",
      "Current loss value: 5.28102\n",
      "Current loss value: 5.68618\n",
      "Current loss value: 6.09228\n",
      "Current loss value: 6.49943\n",
      "Current loss value: 6.91056\n",
      "Current loss value: 7.32437\n",
      "Current loss value: 7.73903\n",
      "Current loss value: 8.15456\n",
      "Current loss value: 8.57099\n",
      "Current loss value: 8.98825\n",
      "Current loss value: 9.40702\n",
      "Current loss value: 9.82641\n",
      "Current loss value: 10.2464\n",
      "Filter 2 processed in 0s\n",
      "Processing filter 3\n",
      "Current loss value: 2.36473\n",
      "Current loss value: 2.72554\n",
      "Current loss value: 3.09254\n",
      "Current loss value: 3.4654\n",
      "Current loss value: 3.84101\n",
      "Current loss value: 4.2193\n",
      "Current loss value: 4.60248\n",
      "Current loss value: 4.98758\n",
      "Current loss value: 5.3767\n",
      "Current loss value: 5.77047\n",
      "Current loss value: 6.16736\n",
      "Current loss value: 6.56658\n",
      "Current loss value: 6.9675\n",
      "Current loss value: 7.36914\n",
      "Current loss value: 7.77162\n",
      "Current loss value: 8.17521\n",
      "Current loss value: 8.58142\n",
      "Current loss value: 8.98951\n",
      "Current loss value: 9.39819\n",
      "Current loss value: 9.80745\n",
      "Filter 3 processed in 0s\n",
      "Processing filter 4\n",
      "Current loss value: 1.88367\n",
      "Current loss value: 2.23295\n",
      "Current loss value: 2.59048\n",
      "Current loss value: 2.95443\n",
      "Current loss value: 3.32443\n",
      "Current loss value: 3.69994\n",
      "Current loss value: 4.07991\n",
      "Current loss value: 4.46558\n",
      "Current loss value: 4.85315\n",
      "Current loss value: 5.24623\n",
      "Current loss value: 5.64291\n",
      "Current loss value: 6.04288\n",
      "Current loss value: 6.44408\n",
      "Current loss value: 6.84639\n",
      "Current loss value: 7.25165\n",
      "Current loss value: 7.65957\n",
      "Current loss value: 8.07042\n",
      "Current loss value: 8.4829\n",
      "Current loss value: 8.89868\n",
      "Current loss value: 9.31617\n",
      "Filter 4 processed in 0s\n",
      "Processing filter 5\n",
      "Current loss value: 2.18115\n",
      "Current loss value: 2.56157\n",
      "Current loss value: 2.95103\n",
      "Current loss value: 3.35115\n",
      "Current loss value: 3.75463\n",
      "Current loss value: 4.16258\n",
      "Current loss value: 4.57977\n",
      "Current loss value: 5.00146\n",
      "Current loss value: 5.42621\n",
      "Current loss value: 5.85303\n",
      "Current loss value: 6.28349\n",
      "Current loss value: 6.71545\n",
      "Current loss value: 7.15007\n",
      "Current loss value: 7.5878\n",
      "Current loss value: 8.02969\n",
      "Current loss value: 8.4747\n",
      "Current loss value: 8.92\n",
      "Current loss value: 9.36623\n",
      "Current loss value: 9.81301\n",
      "Current loss value: 10.2604\n",
      "Filter 5 processed in 0s\n",
      "Processing filter 6\n",
      "Current loss value: 2.36984\n",
      "Current loss value: 2.75407\n",
      "Current loss value: 3.14298\n",
      "Current loss value: 3.53621\n",
      "Current loss value: 3.93217\n",
      "Current loss value: 4.33386\n",
      "Current loss value: 4.74047\n",
      "Current loss value: 5.1514\n",
      "Current loss value: 5.56599\n",
      "Current loss value: 5.98433\n",
      "Current loss value: 6.40418\n",
      "Current loss value: 6.8243\n",
      "Current loss value: 7.24536\n",
      "Current loss value: 7.66869\n",
      "Current loss value: 8.09502\n",
      "Current loss value: 8.52219\n",
      "Current loss value: 8.94976\n",
      "Current loss value: 9.37905\n",
      "Current loss value: 9.80931\n",
      "Current loss value: 10.2411\n",
      "Filter 6 processed in 0s\n",
      "Processing filter 7\n",
      "Current loss value: 1.87092\n",
      "Current loss value: 2.12224\n",
      "Current loss value: 2.37443\n",
      "Current loss value: 2.62716\n",
      "Current loss value: 2.8799\n",
      "Current loss value: 3.13268\n",
      "Current loss value: 3.38601\n",
      "Current loss value: 3.63934\n",
      "Current loss value: 3.89282\n",
      "Current loss value: 4.14687\n",
      "Current loss value: 4.40149\n",
      "Current loss value: 4.6561\n",
      "Current loss value: 4.91071\n",
      "Current loss value: 5.16532\n",
      "Current loss value: 5.41993\n",
      "Current loss value: 5.67465\n",
      "Current loss value: 5.93067\n",
      "Current loss value: 6.1873\n",
      "Current loss value: 6.44397\n",
      "Current loss value: 6.70124\n",
      "Filter 7 processed in 0s\n",
      "Processing filter 8\n",
      "Current loss value: 2.00906\n",
      "Current loss value: 2.3658\n",
      "Current loss value: 2.73532\n",
      "Current loss value: 3.11499\n",
      "Current loss value: 3.50142\n",
      "Current loss value: 3.89161\n",
      "Current loss value: 4.28661\n",
      "Current loss value: 4.68501\n",
      "Current loss value: 5.08606\n",
      "Current loss value: 5.48857\n",
      "Current loss value: 5.89109\n",
      "Current loss value: 6.29445\n",
      "Current loss value: 6.7009\n",
      "Current loss value: 7.10893\n",
      "Current loss value: 7.51767\n",
      "Current loss value: 7.92773\n",
      "Current loss value: 8.33825\n",
      "Current loss value: 8.74951\n",
      "Current loss value: 9.16146\n",
      "Current loss value: 9.57385\n",
      "Filter 8 processed in 0s\n",
      "Processing filter 9\n",
      "Current loss value: 2.07616\n",
      "Current loss value: 2.40919\n",
      "Current loss value: 2.74998\n",
      "Current loss value: 3.09244\n",
      "Current loss value: 3.43808\n",
      "Current loss value: 3.78756\n",
      "Current loss value: 4.14005\n",
      "Current loss value: 4.4957\n",
      "Current loss value: 4.8548\n",
      "Current loss value: 5.21632\n",
      "Current loss value: 5.57987\n",
      "Current loss value: 5.94353\n",
      "Current loss value: 6.30859\n",
      "Current loss value: 6.67475\n",
      "Current loss value: 7.04387\n",
      "Current loss value: 7.4145\n",
      "Current loss value: 7.78732\n",
      "Current loss value: 8.16103\n",
      "Current loss value: 8.53652\n",
      "Current loss value: 8.9125\n",
      "Filter 9 processed in 0s\n",
      "Processing filter 10\n",
      "Current loss value: 2.11862\n",
      "Current loss value: 2.61567\n",
      "Current loss value: 3.12051\n",
      "Current loss value: 3.63898\n",
      "Current loss value: 4.16989\n",
      "Current loss value: 4.71166\n",
      "Current loss value: 5.26115\n",
      "Current loss value: 5.82015\n",
      "Current loss value: 6.38889\n",
      "Current loss value: 6.96561\n",
      "Current loss value: 7.55218\n",
      "Current loss value: 8.14734\n",
      "Current loss value: 8.75085\n",
      "Current loss value: 9.35821\n",
      "Current loss value: 9.97271\n",
      "Current loss value: 10.5943\n",
      "Current loss value: 11.2223\n",
      "Current loss value: 11.854\n",
      "Current loss value: 12.4898\n",
      "Current loss value: 13.127\n",
      "Filter 10 processed in 0s\n",
      "Processing filter 11\n",
      "Current loss value: 2.04362\n",
      "Current loss value: 2.46466\n",
      "Current loss value: 2.89422\n",
      "Current loss value: 3.33316\n",
      "Current loss value: 3.77692\n",
      "Current loss value: 4.22475\n",
      "Current loss value: 4.67604\n",
      "Current loss value: 5.13281\n",
      "Current loss value: 5.59295\n",
      "Current loss value: 6.05648\n",
      "Current loss value: 6.52242\n",
      "Current loss value: 6.99001\n",
      "Current loss value: 7.46129\n",
      "Current loss value: 7.93577\n",
      "Current loss value: 8.41129\n",
      "Current loss value: 8.89005\n",
      "Current loss value: 9.37051\n",
      "Current loss value: 9.8552\n",
      "Current loss value: 10.342\n",
      "Current loss value: 10.8301\n",
      "Filter 11 processed in 0s\n",
      "Processing filter 12\n",
      "Current loss value: 1.42694\n",
      "Current loss value: 1.63895\n",
      "Current loss value: 1.855\n",
      "Current loss value: 2.07285\n",
      "Current loss value: 2.29333\n",
      "Current loss value: 2.5161\n",
      "Current loss value: 2.74027\n",
      "Current loss value: 2.96758\n",
      "Current loss value: 3.19564\n",
      "Current loss value: 3.42466\n",
      "Current loss value: 3.65465\n",
      "Current loss value: 3.88757\n",
      "Current loss value: 4.12199\n",
      "Current loss value: 4.35823\n",
      "Current loss value: 4.5957\n",
      "Current loss value: 4.83318\n",
      "Current loss value: 5.07116\n",
      "Current loss value: 5.31179\n",
      "Current loss value: 5.5542\n",
      "Current loss value: 5.79834\n",
      "Filter 12 processed in 0s\n",
      "Processing filter 13\n",
      "Current loss value: 2.29472\n",
      "Current loss value: 2.61634\n",
      "Current loss value: 2.93876\n",
      "Current loss value: 3.26189\n",
      "Current loss value: 3.5876\n",
      "Current loss value: 3.91517\n",
      "Current loss value: 4.24443\n",
      "Current loss value: 4.57369\n",
      "Current loss value: 4.90346\n",
      "Current loss value: 5.2353\n",
      "Current loss value: 5.5684\n",
      "Current loss value: 5.90223\n",
      "Current loss value: 6.23631\n",
      "Current loss value: 6.57169\n",
      "Current loss value: 6.90708\n",
      "Current loss value: 7.24246\n",
      "Current loss value: 7.57866\n",
      "Current loss value: 7.91596\n",
      "Current loss value: 8.25492\n",
      "Current loss value: 8.59627\n",
      "Filter 13 processed in 0s\n",
      "Processing filter 14\n",
      "Current loss value: 1.52804\n",
      "Current loss value: 1.79561\n",
      "Current loss value: 2.06546\n",
      "Current loss value: 2.33898\n",
      "Current loss value: 2.61858\n",
      "Current loss value: 2.90342\n",
      "Current loss value: 3.19205\n",
      "Current loss value: 3.48399\n",
      "Current loss value: 3.77765\n",
      "Current loss value: 4.07328\n",
      "Current loss value: 4.36936\n",
      "Current loss value: 4.66616\n",
      "Current loss value: 4.96532\n",
      "Current loss value: 5.26571\n",
      "Current loss value: 5.56717\n",
      "Current loss value: 5.87037\n",
      "Current loss value: 6.17491\n",
      "Current loss value: 6.48033\n",
      "Current loss value: 6.78816\n",
      "Current loss value: 7.09711\n",
      "Filter 14 processed in 0s\n",
      "Processing filter 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss value: 1.54155\n",
      "Current loss value: 1.79834\n",
      "Current loss value: 2.06008\n",
      "Current loss value: 2.32572\n",
      "Current loss value: 2.59497\n",
      "Current loss value: 2.86774\n",
      "Current loss value: 3.14504\n",
      "Current loss value: 3.42739\n",
      "Current loss value: 3.71341\n",
      "Current loss value: 4.00227\n",
      "Current loss value: 4.29463\n",
      "Current loss value: 4.59036\n",
      "Current loss value: 4.88862\n",
      "Current loss value: 5.18938\n",
      "Current loss value: 5.49134\n",
      "Current loss value: 5.79504\n",
      "Current loss value: 6.10003\n",
      "Current loss value: 6.4054\n",
      "Current loss value: 6.71115\n",
      "Current loss value: 7.01725\n",
      "Filter 15 processed in 0s\n",
      "Processing filter 16\n",
      "Current loss value: 1.62804\n",
      "Current loss value: 2.15277\n",
      "Current loss value: 2.71905\n",
      "Current loss value: 3.32183\n",
      "Current loss value: 3.9554\n",
      "Current loss value: 4.62368\n",
      "Current loss value: 5.327\n",
      "Current loss value: 6.0476\n",
      "Current loss value: 6.79029\n",
      "Current loss value: 7.56215\n",
      "Current loss value: 8.35564\n",
      "Current loss value: 9.16768\n",
      "Current loss value: 10.0024\n",
      "Current loss value: 10.8559\n",
      "Current loss value: 11.7282\n",
      "Current loss value: 12.6184\n",
      "Current loss value: 13.5174\n",
      "Current loss value: 14.4234\n",
      "Current loss value: 15.3358\n",
      "Current loss value: 16.2525\n",
      "Filter 16 processed in 0s\n",
      "Processing filter 17\n",
      "Current loss value: 2.38149\n",
      "Current loss value: 2.7544\n",
      "Current loss value: 3.1329\n",
      "Current loss value: 3.51757\n",
      "Current loss value: 3.90833\n",
      "Current loss value: 4.30085\n",
      "Current loss value: 4.69549\n",
      "Current loss value: 5.09441\n",
      "Current loss value: 5.49741\n",
      "Current loss value: 5.90743\n",
      "Current loss value: 6.32177\n",
      "Current loss value: 6.74124\n",
      "Current loss value: 7.16159\n",
      "Current loss value: 7.58242\n",
      "Current loss value: 8.00517\n",
      "Current loss value: 8.4316\n",
      "Current loss value: 8.86206\n",
      "Current loss value: 9.29397\n",
      "Current loss value: 9.72595\n",
      "Current loss value: 10.1589\n",
      "Filter 17 processed in 0s\n",
      "Processing filter 18\n",
      "Current loss value: 1.68849\n",
      "Current loss value: 1.93451\n",
      "Current loss value: 2.18375\n",
      "Current loss value: 2.43509\n",
      "Current loss value: 2.69141\n",
      "Current loss value: 2.95018\n",
      "Current loss value: 3.21033\n",
      "Current loss value: 3.47295\n",
      "Current loss value: 3.73714\n",
      "Current loss value: 4.00306\n",
      "Current loss value: 4.27133\n",
      "Current loss value: 4.53975\n",
      "Current loss value: 4.809\n",
      "Current loss value: 5.07969\n",
      "Current loss value: 5.35159\n",
      "Current loss value: 5.62436\n",
      "Current loss value: 5.8978\n",
      "Current loss value: 6.17231\n",
      "Current loss value: 6.44797\n",
      "Current loss value: 6.72451\n",
      "Filter 18 processed in 0s\n",
      "Processing filter 19\n",
      "Current loss value: 2.07499\n",
      "Current loss value: 2.40796\n",
      "Current loss value: 2.74952\n",
      "Current loss value: 3.09604\n",
      "Current loss value: 3.44745\n",
      "Current loss value: 3.80114\n",
      "Current loss value: 4.15758\n",
      "Current loss value: 4.51837\n",
      "Current loss value: 4.88329\n",
      "Current loss value: 5.25058\n",
      "Current loss value: 5.62151\n",
      "Current loss value: 5.99609\n",
      "Current loss value: 6.37073\n",
      "Current loss value: 6.74702\n",
      "Current loss value: 7.12347\n",
      "Current loss value: 7.50076\n",
      "Current loss value: 7.87888\n",
      "Current loss value: 8.25771\n",
      "Current loss value: 8.64041\n",
      "Current loss value: 9.02368\n",
      "Filter 19 processed in 0s\n",
      "Processing filter 20\n",
      "Current loss value: 2.07657\n",
      "Current loss value: 2.51483\n",
      "Current loss value: 2.96872\n",
      "Current loss value: 3.4355\n",
      "Current loss value: 3.90749\n",
      "Current loss value: 4.38563\n",
      "Current loss value: 4.87202\n",
      "Current loss value: 5.36164\n",
      "Current loss value: 5.86032\n",
      "Current loss value: 6.36612\n",
      "Current loss value: 6.87592\n",
      "Current loss value: 7.38838\n",
      "Current loss value: 7.90572\n",
      "Current loss value: 8.42536\n",
      "Current loss value: 8.94665\n",
      "Current loss value: 9.47073\n",
      "Current loss value: 9.9994\n",
      "Current loss value: 10.532\n",
      "Current loss value: 11.069\n",
      "Current loss value: 11.6075\n",
      "Filter 20 processed in 0s\n",
      "Processing filter 21\n",
      "Current loss value: 1.91911\n",
      "Current loss value: 2.22278\n",
      "Current loss value: 2.52982\n",
      "Current loss value: 2.84052\n",
      "Current loss value: 3.15284\n",
      "Current loss value: 3.46615\n",
      "Current loss value: 3.78151\n",
      "Current loss value: 4.09829\n",
      "Current loss value: 4.41552\n",
      "Current loss value: 4.73308\n",
      "Current loss value: 5.05159\n",
      "Current loss value: 5.37062\n",
      "Current loss value: 5.6901\n",
      "Current loss value: 6.00959\n",
      "Current loss value: 6.32908\n",
      "Current loss value: 6.64907\n",
      "Current loss value: 6.9711\n",
      "Current loss value: 7.29464\n",
      "Current loss value: 7.61817\n",
      "Current loss value: 7.94202\n",
      "Filter 21 processed in 0s\n",
      "Processing filter 22\n",
      "Current loss value: 2.22455\n",
      "Current loss value: 2.54157\n",
      "Current loss value: 2.86298\n",
      "Current loss value: 3.1899\n",
      "Current loss value: 3.52693\n",
      "Current loss value: 3.86953\n",
      "Current loss value: 4.21285\n",
      "Current loss value: 4.56033\n",
      "Current loss value: 4.91379\n",
      "Current loss value: 5.27182\n",
      "Current loss value: 5.63332\n",
      "Current loss value: 5.99661\n",
      "Current loss value: 6.36353\n",
      "Current loss value: 6.73393\n",
      "Current loss value: 7.10814\n",
      "Current loss value: 7.48395\n",
      "Current loss value: 7.86183\n",
      "Current loss value: 8.24182\n",
      "Current loss value: 8.6246\n",
      "Current loss value: 9.00803\n",
      "Filter 22 processed in 0s\n",
      "Processing filter 23\n",
      "Current loss value: 1.98721\n",
      "Current loss value: 2.45478\n",
      "Current loss value: 2.93768\n",
      "Current loss value: 3.4331\n",
      "Current loss value: 3.93937\n",
      "Current loss value: 4.45804\n",
      "Current loss value: 4.98823\n",
      "Current loss value: 5.5267\n",
      "Current loss value: 6.07134\n",
      "Current loss value: 6.62134\n",
      "Current loss value: 7.17641\n",
      "Current loss value: 7.73736\n",
      "Current loss value: 8.30103\n",
      "Current loss value: 8.86961\n",
      "Current loss value: 9.44278\n",
      "Current loss value: 10.0211\n",
      "Current loss value: 10.6026\n",
      "Current loss value: 11.1864\n",
      "Current loss value: 11.7738\n",
      "Current loss value: 12.3623\n",
      "Filter 23 processed in 0s\n",
      "Processing filter 24\n",
      "Current loss value: 2.22033\n",
      "Current loss value: 2.55811\n",
      "Current loss value: 2.90425\n",
      "Current loss value: 3.25344\n",
      "Current loss value: 3.60592\n",
      "Current loss value: 3.96106\n",
      "Current loss value: 4.31764\n",
      "Current loss value: 4.676\n",
      "Current loss value: 5.03575\n",
      "Current loss value: 5.39855\n",
      "Current loss value: 5.76304\n",
      "Current loss value: 6.13111\n",
      "Current loss value: 6.49995\n",
      "Current loss value: 6.87012\n",
      "Current loss value: 7.24152\n",
      "Current loss value: 7.61538\n",
      "Current loss value: 7.99075\n",
      "Current loss value: 8.36747\n",
      "Current loss value: 8.74567\n",
      "Current loss value: 9.12447\n",
      "Filter 24 processed in 0s\n",
      "Processing filter 25\n",
      "Current loss value: 2.4412\n",
      "Current loss value: 2.88187\n",
      "Current loss value: 3.32883\n",
      "Current loss value: 3.78487\n",
      "Current loss value: 4.25171\n",
      "Current loss value: 4.72704\n",
      "Current loss value: 5.20604\n",
      "Current loss value: 5.68918\n",
      "Current loss value: 6.1773\n",
      "Current loss value: 6.66854\n",
      "Current loss value: 7.16095\n",
      "Current loss value: 7.65622\n",
      "Current loss value: 8.15352\n",
      "Current loss value: 8.65593\n",
      "Current loss value: 9.16463\n",
      "Current loss value: 9.67768\n",
      "Current loss value: 10.1949\n",
      "Current loss value: 10.7184\n",
      "Current loss value: 11.244\n",
      "Current loss value: 11.7705\n",
      "Filter 25 processed in 0s\n",
      "Processing filter 26\n",
      "Current loss value: 1.68058\n",
      "Current loss value: 1.98765\n",
      "Current loss value: 2.29923\n",
      "Current loss value: 2.61519\n",
      "Current loss value: 2.9385\n",
      "Current loss value: 3.26976\n",
      "Current loss value: 3.60432\n",
      "Current loss value: 3.94404\n",
      "Current loss value: 4.28647\n",
      "Current loss value: 4.63219\n",
      "Current loss value: 4.97923\n",
      "Current loss value: 5.32882\n",
      "Current loss value: 5.67986\n",
      "Current loss value: 6.03339\n",
      "Current loss value: 6.38752\n",
      "Current loss value: 6.74348\n",
      "Current loss value: 7.10169\n",
      "Current loss value: 7.46164\n",
      "Current loss value: 7.82342\n",
      "Current loss value: 8.18647\n",
      "Filter 26 processed in 0s\n",
      "Processing filter 27\n",
      "Current loss value: 2.09849\n",
      "Current loss value: 2.41401\n",
      "Current loss value: 2.7305\n",
      "Current loss value: 3.048\n",
      "Current loss value: 3.36758\n",
      "Current loss value: 3.68778\n",
      "Current loss value: 4.00876\n",
      "Current loss value: 4.33177\n",
      "Current loss value: 4.6569\n",
      "Current loss value: 4.98335\n",
      "Current loss value: 5.30986\n",
      "Current loss value: 5.63714\n",
      "Current loss value: 5.96614\n",
      "Current loss value: 6.29516\n",
      "Current loss value: 6.62497\n",
      "Current loss value: 6.95478\n",
      "Current loss value: 7.28484\n",
      "Current loss value: 7.61596\n",
      "Current loss value: 7.94757\n",
      "Current loss value: 8.27964\n",
      "Filter 27 processed in 0s\n",
      "Processing filter 28\n",
      "Current loss value: 2.01902\n",
      "Current loss value: 2.40066\n",
      "Current loss value: 2.79233\n",
      "Current loss value: 3.1881\n",
      "Current loss value: 3.58889\n",
      "Current loss value: 3.99339\n",
      "Current loss value: 4.40367\n",
      "Current loss value: 4.81855\n",
      "Current loss value: 5.2374\n",
      "Current loss value: 5.66067\n",
      "Current loss value: 6.08948\n",
      "Current loss value: 6.52414\n",
      "Current loss value: 6.96088\n",
      "Current loss value: 7.40115\n",
      "Current loss value: 7.84336\n",
      "Current loss value: 8.28811\n",
      "Current loss value: 8.7349\n",
      "Current loss value: 9.18449\n",
      "Current loss value: 9.63786\n",
      "Current loss value: 10.094\n",
      "Filter 28 processed in 0s\n",
      "Processing filter 29\n",
      "Current loss value: 2.18229\n",
      "Current loss value: 2.51875\n",
      "Current loss value: 2.85997\n",
      "Current loss value: 3.20454\n",
      "Current loss value: 3.55307\n",
      "Current loss value: 3.90561\n",
      "Current loss value: 4.2622\n",
      "Current loss value: 4.61888\n",
      "Current loss value: 4.97613\n",
      "Current loss value: 5.33358\n",
      "Current loss value: 5.6919\n",
      "Current loss value: 6.05206\n",
      "Current loss value: 6.41403\n",
      "Current loss value: 6.77848\n",
      "Current loss value: 7.14333\n",
      "Current loss value: 7.50988\n",
      "Current loss value: 7.87719\n",
      "Current loss value: 8.24532\n",
      "Current loss value: 8.61345\n",
      "Current loss value: 8.98157\n",
      "Filter 29 processed in 0s\n",
      "Processing filter 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss value: 1.96931\n",
      "Current loss value: 2.35653\n",
      "Current loss value: 2.75243\n",
      "Current loss value: 3.15534\n",
      "Current loss value: 3.56278\n",
      "Current loss value: 3.97944\n",
      "Current loss value: 4.40215\n",
      "Current loss value: 4.83033\n",
      "Current loss value: 5.26153\n",
      "Current loss value: 5.69776\n",
      "Current loss value: 6.14043\n",
      "Current loss value: 6.58923\n",
      "Current loss value: 7.04208\n",
      "Current loss value: 7.50065\n",
      "Current loss value: 7.9661\n",
      "Current loss value: 8.4355\n",
      "Current loss value: 8.90833\n",
      "Current loss value: 9.38596\n",
      "Current loss value: 9.86672\n",
      "Current loss value: 10.3498\n",
      "Filter 30 processed in 0s\n",
      "Processing filter 31\n",
      "Current loss value: 1.57109\n",
      "Current loss value: 2.10808\n",
      "Current loss value: 2.68212\n",
      "Current loss value: 3.28902\n",
      "Current loss value: 3.9407\n",
      "Current loss value: 4.6323\n",
      "Current loss value: 5.35867\n",
      "Current loss value: 6.1174\n",
      "Current loss value: 6.91276\n",
      "Current loss value: 7.73177\n",
      "Current loss value: 8.57415\n",
      "Current loss value: 9.43405\n",
      "Current loss value: 10.3051\n",
      "Current loss value: 11.189\n",
      "Current loss value: 12.0824\n",
      "Current loss value: 12.9885\n",
      "Current loss value: 13.9066\n",
      "Current loss value: 14.8296\n",
      "Current loss value: 15.7564\n",
      "Current loss value: 16.6851\n",
      "Filter 31 processed in 0s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "# dimensions of the generated pictures for each filter.\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "layer_name = 'conv2d_1'\n",
    "# this is the placeholder for the input images\n",
    "input_img = model.input\n",
    "\n",
    "kept_filters = []\n",
    "for filter_index in range(0, 32):\n",
    "    # we only scan through the first 200 filters,\n",
    "    # but there are actually 512 of them\n",
    "    print('Processing filter %d' % filter_index)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # we build a loss function that maximizes the activation\n",
    "    # of the nth filter of the layer considered\n",
    "    layer_output = layer_dict[layer_name].output\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        loss = K.mean(layer_output[:, filter_index, :, :])\n",
    "    else:\n",
    "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "    # we compute the gradient of the input picture wrt this loss\n",
    "    grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "    # normalization trick: we normalize the gradient\n",
    "    grads = normalize(grads)\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    iterate = K.function([input_img], [loss, grads])\n",
    "\n",
    "    # step size for gradient ascent\n",
    "    step = 1.\n",
    "\n",
    "    # we start from a gray image with some random noise\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_img_data = np.random.random((1, 1, img_width, img_height))\n",
    "    else:\n",
    "        input_img_data = np.random.random((1, img_width, img_height, 1))\n",
    "    input_img_data = (input_img_data - 0.5) * 40\n",
    "\n",
    "    # we run gradient ascent for 20 steps\n",
    "    for i in range(20):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "\n",
    "        print('Current loss value:', loss_value)\n",
    "        if loss_value <= 0.:\n",
    "            # some filters get stuck to 0, we can skip them\n",
    "            break\n",
    "\n",
    "    # decode the resulting input image\n",
    "    if loss_value > 0:\n",
    "        img = deprocess_image(input_img_data[0])\n",
    "        kept_filters.append((img, loss_value))\n",
    "    end_time = time.time()\n",
    "    print('Filter %d processed in %ds' % (filter_index, end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imsave\n",
    "# we will stich the best 16 filters on a 8 x 8 grid.\n",
    "n = 4\n",
    "\n",
    "# the filters that have the highest loss are assumed to be better-looking.\n",
    "# we will only keep the top 16 filters.\n",
    "kept_filters.sort(key=lambda x: x[1], reverse=True)\n",
    "kept_filters = kept_filters[:n * n]\n",
    "\n",
    "# build a black picture with enough space for\n",
    "# our 4 x 4 filters of size 28 x 28, with a 5px margin in between\n",
    "margin = 5\n",
    "width = n * img_width + (n - 1) * margin\n",
    "height = n * img_height + (n - 1) * margin\n",
    "stitched_filters = np.zeros((width, height, 3))\n",
    "\n",
    "# fill the picture with our saved filters\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        img, loss = kept_filters[i * n + j]\n",
    "        stitched_filters[(img_width + margin) * i: (img_width + margin) * i + img_width,\n",
    "                         (img_height + margin) * j: (img_height + margin) * j + img_height, :] = img\n",
    "\n",
    "# save the result to disk\n",
    "imsave('stitched_filters_%dx%d.png' % (n, n), stitched_filters)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
